{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "#modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('mpesa_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top of the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom of the data\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for columns that do not have data\n",
    "empty_columns = df.columns[df.isna().all()].to_list()\n",
    "print('Columns with no data:', empty_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in each column\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame to avoid modifying the CSV\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in \"Paid In\" and \"Withdrawn\" with 0\n",
    "data['Paid In'] = data['Paid In'].fillna(0)\n",
    "data['Withdrawn'] = data['Withdrawn'].fillna(0)\n",
    "\n",
    "# check data\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in \"Details\" with 'Other'\n",
    "data['Details'] = data['Details'].fillna('Other')\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any data has been lost\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any duplicated rows\n",
    "print(\"Number of duplicated rows:\", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. classify transactions as 'Withdraw' (1) if Withdrawn == 0.0, else 'Paid in' (0)\n",
    "\n",
    "data['Type'] = data['Withdrawn'].apply(lambda x: 1 if x==0.0 else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. function to categorize the transaction details\n",
    "def category_details(details):\n",
    "\n",
    "    # convert the details to lowercase\n",
    "    details = str(details).lower()\n",
    "\n",
    "    if any(word in details for word in [\"airtime\", \"tingg\", \"safaricom\", \"airtel\", \"bundles\", \"gessy\"]):\n",
    "        return \"Airtime\"\n",
    " \n",
    "    elif any(word in details for word in [\"kplc\"]):\n",
    "        return \"Power\"\n",
    "    elif any(word in details for word in [\"7629905\"]):\n",
    "        return \"Rent Payment\"\n",
    "\n",
    "    elif any(word in details for word in [\"cleanshelf\", \"equity\", \"kcb\",\"naivas\", \"tuskys\", \"quick mart\", \"carrefour\", \"4093275\",\"supermarket\", \"shopping\", \"small business\", \"mall\",\"jumia\", \"kilimall\", \"amazon\", \"shop\", \"market\", \"merchant\", \"direct pay\"]):\n",
    "        return \"Shopping\"\n",
    "    elif any(word in details for word in [\"baraka\", \"java\", \"hotel\", \"restaurant\", \"cafe\"]):\n",
    "        return \"Restaurant\"\n",
    "    elif any(word in details for word in [\"sacco\", \"uber\"]):\n",
    "        return \"Transport\"\n",
    "    elif any(word in details for word in [\"alpha\", \"water\"]):\n",
    "        return \"Water\"\n",
    "    elif any(word in details for word in [\"butchery\", \"meat\", \"butcher\"]):\n",
    "        return \"Butchery\"\n",
    "    elif any(word in details for word in [\"customer transfer\"]):\n",
    "        return \"People Transfer\"\n",
    "    elif any(word in details for word in [\"withdraw\"]):\n",
    "        return \"Withdrawals\"\n",
    "    elif any(word in details for word in [\"charge\"]):\n",
    "        return \"Transaction Charge\"\n",
    "\n",
    "    elif any(word in details for word in [\"pay bill\"]):\n",
    "        return \"Pay Bill\"\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function on the \"Details\" column\n",
    "data['Category'] = data['Details'].apply(category_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check value counts in each category\n",
    "data['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''remove the transactions that were paid into your account and only remain with transactions withdrawn from account, \n",
    "because we are interested in the spending pattern'''\n",
    "\n",
    "df= data[data['Type'] == 0].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour, day and month from the time column\n",
    "df['Hour'] = pd.to_datetime(df['Completion Time']).dt.hour\n",
    "\n",
    "df['DayOfWeek'] = pd.to_datetime(df['Completion Time']).dt.day_name()\n",
    "\n",
    "df['Month'] = pd.to_datetime(df['Completion Time']).dt.month\n",
    "\n",
    "df['MonthName'] = pd.to_datetime(df['Completion Time']).dt.month_name()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the net movement (amount)\n",
    "df['Amount'] = df['Paid In'] - df['Withdrawn']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding to the category column\n",
    "category_dummies = pd.get_dummies(df['Category'], prefix='Category')\n",
    "# convert the dummies to integer type and add a prefix\n",
    "category_dummies = category_dummies.astype(int).add_prefix('Converted_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the category dummies with the original dataframe\n",
    "df_clean = pd.concat([df, category_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding on the time columns\n",
    "# day of the week\n",
    "dayofweek_dummies = pd.get_dummies(df_clean['DayOfWeek'], prefix='DayOfWeek')\n",
    "dayofweek_dummies = dayofweek_dummies.astype(int).add_prefix('Converted_')\n",
    "\n",
    "# concatenate the dayofweek_dummies to original df\n",
    "df_clean = pd.concat([df_clean, dayofweek_dummies], axis=1)\n",
    "\n",
    "# hour\n",
    "hour_dummies = pd.get_dummies(df_clean['Hour'], prefix='Hour')\n",
    "hour_dummies = hour_dummies.astype(int).add_prefix('Converted_')\n",
    "\n",
    "# concatenate the hour_dummies to original df\n",
    "df_clean = pd.concat([df_clean, hour_dummies], axis=1)\n",
    "\n",
    "# month\n",
    "month_dummies = pd.get_dummies(df_clean['Month'], prefix='Month')\n",
    "month_dummies = month_dummies.astype(int).add_prefix('Converted_')\n",
    "\n",
    "# concatenate original df with month_dummies\n",
    "df_clean = pd.concat([df_clean, month_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the encoded columns\n",
    "encoded_columns = [col for col in df_clean.columns if col.startswith('Converted_')]\n",
    "encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the features into a single dataframe including \"Amount\" column\n",
    "clustering_data = pd.concat([df_clean[encoded_columns], df_clean[['Amount']]], axis=1)\n",
    "clustering_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the datatypes on the data\n",
    "clustering_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the amount column\n",
    "scaler = StandardScaler()\n",
    "clustering_data['amount'] = scaler.fit_transform(clustering_data[['Amount']])\n",
    "clustering_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the optimum number of clusters using silhoutte method\n",
    "silhouette_scores = []\n",
    "cluster_range = range(2,11) # test cluster sizes 2 - 10\n",
    "\n",
    "for n_clusters in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(clustering_data)\n",
    "    silhouette_avg = silhouette_score(clustering_data, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# plot the silhouette scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cluster_range, silhouette_scores, marker = 'o')\n",
    "plt.title('Silhouette Scores for Different Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# find optimum number of clusters\n",
    "optimal_clusters = cluster_range[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f'Optimal number of clusters is:', optimal_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with the optimum number of clusters\n",
    "model = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "df_clean['purpose_cluster'] = model.fit_predict(clustering_data) # make cluster predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model performance (silhouette score)\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X_scaled = clustering_data.values #Use the scaled data for silhouette score calculation\n",
    "labels = model.predict(X_scaled)\n",
    "\n",
    "# calculate the silhouette score\n",
    "silhouette_average = silhouette_score(X_scaled, labels)\n",
    "print(\"Silhouette Score is: \", silhouette_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average amount, median amount, total amount, and top categories for each cluster\n",
    "\n",
    "cluster_summary = df_clean.groupby('purpose_cluster').agg(\n",
    "    avg_amount = ('Amount', 'mean'), \n",
    "    median_amount = ('Amount', 'median'), \n",
    "    total_amount = ('Amount', 'sum'), # <--- added total amount\n",
    "    count = ('purpose_cluster', 'size')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add top 2 for each type of Converted_ column per cluster\n",
    "def get_top_n_columns(cluster_data, prefix, n=2):\n",
    "    cols = [col for col in cluster_data.columns if col.startswith(prefix)]\n",
    "    counts = cluster_data[cols].sum().sort_values(ascending=False)\n",
    "    unique_top = []\n",
    "    for col in counts.index:\n",
    "        name = col.replace('Converted_', '')\n",
    "        if name not in unique_top:\n",
    "            unique_top.append(name)\n",
    "        if len(unique_top) == n:\n",
    "            break\n",
    "    return \", \".join(unique_top)\n",
    "\n",
    "\n",
    "top_categories = []\n",
    "top_months = []\n",
    "top_days = []\n",
    "top_hours = []\n",
    "\n",
    "for cluster in df_clean['purpose_cluster'].unique():\n",
    "    cluster_data = df_clean[df_clean['purpose_cluster'] == cluster]\n",
    "    top_categories.append(get_top_n_columns(cluster_data, 'Converted_Category'))\n",
    "    top_months.append(get_top_n_columns(cluster_data, 'Converted_Month'))\n",
    "    top_days.append(get_top_n_columns(cluster_data, 'Converted_DayOfWeek'))\n",
    "    top_hours.append(get_top_n_columns(cluster_data, 'Converted_Hour'))\n",
    "\n",
    "cluster_summary['top_categories'] = top_categories\n",
    "cluster_summary['top_months'] = top_months\n",
    "cluster_summary['top_days'] = top_days\n",
    "cluster_summary['top_hours'] = top_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Category_Other' from the top_categories column in the summary (so it doesn't show in the output)\n",
    "cluster_summary['top_categories'] = cluster_summary['top_categories'].apply(\n",
    "    lambda x: \", \".join([cat for cat in x.split(\", \") if cat != \"Category_Other\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display cluster summary\n",
    "print(cluster_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of Hour of the Day vs Total Amount Spent\n",
    "amount_by_hour = df_clean.groupby('Hour')['Amount'].sum().reindex(range(24))\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=amount_by_hour.index, y=amount_by_hour.values, palette='viridis', hue=amount_by_hour.index, legend=False)\n",
    "plt.title('Total Amount Spent by Hour of the Day')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Total Amount Spent')\n",
    "plt.xticks(range(24))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of Day of the Week vs Total Amount Spent\n",
    "amount_by_day = df_clean.groupby('DayOfWeek')['Amount'].sum().reindex([\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "])\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=amount_by_day.index, y=amount_by_day.values, palette='viridis', hue=amount_by_day.index, legend=False)\n",
    "plt.title('Total Amount Spent by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Total Amount Spent')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of Category vs Total Amount Spent\n",
    "amount_by_category = df_clean.groupby('Category')['Amount'].sum().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=amount_by_category.index, y=amount_by_category.values, palette='viridis', hue=amount_by_category.index, legend=False)\n",
    "plt.title('Total Amount Spent by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total Amount Spent')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the Other category from the list\n",
    "amount_by_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
